{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../TrainDataset2024.csv', index_col=0)\n",
    "\n",
    "#MISSING DATA\n",
    "data.replace(999, np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns,index=data.index)\n",
    "\n",
    "\n",
    "target = data[['RelapseFreeSurvival (outcome)']]#'pCR (outcome)']]\n",
    "data.drop(columns=['pCR (outcome)','RelapseFreeSurvival (outcome)'], axis=1, inplace=True)\n",
    "\n",
    "key_features = data[['ER', 'HER2', 'Gene']]\n",
    "data.drop(columns=['ER', 'HER2', 'Gene'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NORMALISATION\n",
    "normalizer = Normalizer()\n",
    "vector_normalized_data = normalizer.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE REDUCTION\n",
    "pca = PCA(n_components=0.95)\n",
    "data_reduced = pca.fit_transform(vector_normalized_data)\n",
    "\n",
    "pca_complete = pd.DataFrame(data_reduced, index=data.index)\n",
    "pca_complete = pd.concat([pca_complete, key_features], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'epsilon': [0.01, 0.1, 0.2],  # Epsilon values (larger values will ignore smaller errors)\n",
    "    'kernel': ['rbf']  # RBF is often effective, but you can also test 'linear' and 'poly'\n",
    "}\n",
    "\n",
    "#CHANGE ME\n",
    "model = SVR()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 4\n",
    "\n",
    "def train_model(data):\n",
    "    # Outer K-fold cross-validation\n",
    "    outer_cv = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    data = data.rename(str,axis=\"columns\") \n",
    "    \n",
    "    # Perform nested cross-validation\n",
    "    outer_results = []\n",
    "    for train_idx, test_idx in outer_cv.split(data, target):\n",
    "        # Split data\n",
    "        X_train, X_test = data.iloc[train_idx], data.iloc[test_idx]\n",
    "        y_train, y_test = np.ravel(target.iloc[train_idx]), np.ravel(target.iloc[test_idx])\n",
    "\n",
    "        # Inner loop: Hyperparameter tuning using GridSearchCV\n",
    "        inner_cv = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate on the test set\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        # Collect results using regression metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Collect results\n",
    "        outer_results.append({\n",
    "            \"best_params\": grid_search.best_params_,\n",
    "            \"mse\": mse,\n",
    "            \"r2\": r2,\n",
    "            \"mae\": mae,\n",
    "            \"model_score\": best_model.score(X_test, y_test)\n",
    "        })\n",
    "\n",
    "    # Print the results for each fold\n",
    "    for i, result in enumerate(outer_results, 1):\n",
    "        print(f\"Fold {i}\")\n",
    "        print(f\"Best Parameters: {result['best_params']}\")\n",
    "        print(f\"Mean Squared Error (MSE): {result['mse']:.4f}\")\n",
    "        print(f\"R-squared (R²): {result['r2']:.4f}\")\n",
    "        print(f\"Mean Absolute Error (MAE): {result['mae']:.4f}\")\n",
    "        print(f\"Model Score (R² on test set): {result['model_score']:.4f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "    # Overall results\n",
    "    mean_mse = np.mean([res[\"mse\"] for res in outer_results])\n",
    "    mean_r2 = np.mean([res[\"r2\"] for res in outer_results])\n",
    "    mean_mae = np.mean([res[\"mae\"] for res in outer_results])\n",
    "\n",
    "    print(f\"Mean MSE: {mean_mse:.4f}\")\n",
    "    print(f\"Mean R²: {mean_r2:.4f}\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best Parameters: {'C': 1, 'epsilon': 0.2, 'kernel': 'rbf'}\n",
      "Mean Squared Error (MSE): 775.6060\n",
      "R-squared (R²): -0.0133\n",
      "Mean Absolute Error (MAE): 21.6621\n",
      "Model Score (R² on test set): -0.0133\n",
      "----------------------------------------\n",
      "Fold 2\n",
      "Best Parameters: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'}\n",
      "Mean Squared Error (MSE): 725.4279\n",
      "R-squared (R²): 0.0071\n",
      "Mean Absolute Error (MAE): 21.5072\n",
      "Model Score (R² on test set): 0.0071\n",
      "----------------------------------------\n",
      "Fold 3\n",
      "Best Parameters: {'C': 1, 'epsilon': 0.2, 'kernel': 'rbf'}\n",
      "Mean Squared Error (MSE): 669.8834\n",
      "R-squared (R²): -0.0062\n",
      "Mean Absolute Error (MAE): 20.3964\n",
      "Model Score (R² on test set): -0.0062\n",
      "----------------------------------------\n",
      "Fold 4\n",
      "Best Parameters: {'C': 1, 'epsilon': 0.2, 'kernel': 'rbf'}\n",
      "Mean Squared Error (MSE): 783.6476\n",
      "R-squared (R²): -0.0134\n",
      "Mean Absolute Error (MAE): 21.2867\n",
      "Model Score (R² on test set): -0.0134\n",
      "----------------------------------------\n",
      "Mean MSE: 738.6412\n",
      "Mean R²: -0.0064\n",
      "Mean MAE: 21.2131\n"
     ]
    }
   ],
   "source": [
    "train_model(pca_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Train Single Final Model on entire dataset using best-performing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='rbf', C=1,epsilon=0.2)\n",
    "\n",
    "def train_model_single(data):\n",
    "\n",
    "    data = data.rename(str,axis=\"columns\") \n",
    "    \n",
    "    # Split data into 80% training and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print the results\n",
    "    # Calculate the regression metrics\n",
    "    mse = mean_squared_error(np.ravel(y_test), y_pred)\n",
    "    r2 = r2_score(np.ravel(y_test), y_pred)\n",
    "    mae = mean_absolute_error(np.ravel(y_test), y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(f\"R-squared (R²): {r2:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Model Score (R² on test set): {model.score(X_test, np.ravel(y_test)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 800.1768341824876\n",
      "R-squared (R²): -0.0027\n",
      "Mean Absolute Error (MAE): 21.6701\n",
      "Model Score (R² on test set): -0.0027\n"
     ]
    }
   ],
   "source": [
    "train_model_single(pca_complete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
