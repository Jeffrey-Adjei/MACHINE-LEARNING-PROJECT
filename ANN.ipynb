{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d8a0fc-579e-4fe6-865a-75450e18afe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from ucimlrepo) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/MLE/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94e3c3b2-3d92-4185-88ff-2eeb17a6daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b717418-377e-4f8c-b179-9661b2d4c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    # Fetch and load the dataset\n",
    "    car_evaluation = fetch_ucirepo(id=19)\n",
    "    X = car_evaluation.data.features\n",
    "    y = car_evaluation.data.targets\n",
    "\n",
    "    # One-Hot Encode categorical features\n",
    "    X_encoded = pd.get_dummies(X)\n",
    "\n",
    "    # Encode the target variable using LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    return X_encoded, y_encoded, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "76e3754a-2a34-4f85-a17a-1a169eac8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, num_classes):\n",
    "    # Build the model\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf681c25-5b25-4d98-8f25-765c94bc480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train):\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=16,\n",
    "        validation_split=0.1,\n",
    "        verbose=0  \n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1afd4c7-8ddb-4db1-8a8a-81a9d4b41cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, predicted_labels, classes, fold_number):\n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=classes)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title(f'Confusion Matrix - Fold {fold_number}')\n",
    "    plt.savefig(f'confusion_matrix_fold_{fold_number}.png')\n",
    "    plt.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c045596c-85ca-45d5-b13c-fb8e90a05702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(fpr, tpr, roc_auc, classes, fold_number):\n",
    "    # Plot ROC curves\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "\n",
    "    colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown']\n",
    "\n",
    "    for i, color in zip(range(len(classes)), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                       ''.format(classes[i], roc_auc[i]))\n",
    "\n",
    "    # Plot micro-average ROC curve\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    # Plot reference line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic - Fold {fold_number}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(f'roc_curve_fold_{fold_number}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3280cdea-aac6-4b9e-a286-cb281c8f4ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, label_encoder, fold_number):\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Fold {fold_number} - Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold_number} - Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Make predictions (probabilities)\n",
    "    y_score = model.predict(X_test)\n",
    "\n",
    "    # Binarize the output labels\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    y_test_binarized = label_binarize(y_test, classes=range(num_classes))\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plot_roc_curves(fpr, tpr, roc_auc, label_encoder.classes_, fold_number)\n",
    "\n",
    "    # Generate classification report\n",
    "    predicted_classes = tf.argmax(y_score, axis=1).numpy()\n",
    "    predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "    true_labels = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, output_dict=False)\n",
    "    print(f\"Fold {fold_number} - Classification Report:\\n{report}\")\n",
    "    \n",
    "    return test_loss, test_accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "490393b5-a4c7-424b-9b1a-578fcac7cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    X_encoded, y_encoded, label_encoder = load_and_preprocess_data()\n",
    "\n",
    "    # Define number of splits for K-Fold\n",
    "    n_splits = 5  \n",
    "\n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Lists to store metrics for each fold\n",
    "    fold_accuracies = []\n",
    "    fold_losses = []\n",
    "    fold_reports = []\n",
    "\n",
    "    # Start K-Fold Cross-Validation\n",
    "    fold_number = 1\n",
    "    for train_index, test_index in kf.split(X_encoded):\n",
    "        print(f\"\\nStarting Fold {fold_number}/{n_splits}\")\n",
    "\n",
    "        # Split data into training and testing sets for this fold\n",
    "        X_train, X_test = X_encoded.iloc[train_index], X_encoded.iloc[test_index]\n",
    "        y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "        # Get input dimensions and number of classes\n",
    "        input_dim = X_train.shape[1]\n",
    "        num_classes = len(label_encoder.classes_)\n",
    "\n",
    "        # Build the model\n",
    "        model = build_model(input_dim, num_classes)\n",
    "\n",
    "        # Train the model\n",
    "        history = train_model(model, X_train, y_train)\n",
    "\n",
    "        # Evaluate the model and collect results\n",
    "        test_loss, test_accuracy, report = evaluate_model(model, X_test, y_test, label_encoder, fold_number)\n",
    "\n",
    "        # Store metrics for this fold\n",
    "        fold_accuracies.append(test_accuracy)\n",
    "        fold_losses.append(test_loss)\n",
    "        fold_reports.append(report)\n",
    "\n",
    "        fold_number += 1\n",
    "\n",
    "    # Calculate and print average metrics\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_loss = np.mean(fold_losses)\n",
    "    print(f\"\\nAverage Test Accuracy over {n_splits} folds: {avg_accuracy:.4f}\")\n",
    "    print(f\"Average Test Loss over {n_splits} folds: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b683b52-a7cd-478a-bd2f-2ec9115b2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
